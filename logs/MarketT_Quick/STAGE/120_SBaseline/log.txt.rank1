[11/10 16:56:42] fastreid INFO: Rank of current process: 1. World size: 2
[11/10 16:56:43] fastreid INFO: Environment info:
----------------------  ------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Oct 18 2022, 18:57:03) [GCC 11.2.0]
numpy                   1.21.5
fastreid                1.3 @./fastreid
FASTREID_ENV_MODULE     <not set>
PyTorch                 1.12.0 @/home/ckl/anaconda3/envs/fastreid/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1                 NVIDIA GeForce RTX 3090
CUDA_HOME               /usr
Pillow                  9.2.0
torchvision             0.13.0 @/home/ckl/anaconda3/envs/fastreid/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/ckl/anaconda3/envs/fastreid/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
cv2                     4.6.0
----------------------  ------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 16:56:43] fastreid INFO: Command line arguments: Namespace(config_file='./configs/MarketT/SBaseline_Quick.yml', dist_url='tcp://127.0.0.1:50688', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['OUTPUT_DIR', 'logs/MarketT_Quick/STAGE/120_SBaseline', 'MODEL.BACKBONE.NORM', 'syncBN', 'MODEL.HEADS.NORM', 'syncBN'], resume=False)
[11/10 16:56:43] fastreid INFO: Contents of args.config_file=./configs/MarketT/SBaseline_Quick.yml:
_BASE_: ../Base-SBS.yml

DATASETS:
  NAMES: ("Market1501",)
  TESTS: ("Market1501",)

OUTPUT_DIR: logs/MarketT_Quick/Sbaseline_R50

MODEL:
  META_ARCHITECTURE: Sbaseline

  DETACH_ATTN: False # bad

  DETACH_ALL: False # bad

  BACKBONE:
    WITH_IBN: True
    WITH_NL: True
    PRETRAIN: True
    EMBEDDING_DIM: 512

    ATTACH_ACTIVATION: False # bad
    ATTNSHAPED_ACTIVATION: False # bad
    ADJ_KEEP: False

    NORM: BN
    # PRETRAIN_PATH: '/mnt21t/home/mm2022/fast-reid/weights/lup_moco_r50.pth'
    # PRETRAIN_PATH: '/mnt21t/home/mm2022/fast-reid/weights/lupws_r50.pth'

  LOSSES:
    NAME: ("CrossEntropyLoss","TripletLoss",)
        
  HEADS:
    NORM: BN
    ATTN: 8

INPUT:
  AUTOAUG:
    ENABLED: False

  RPT:
    ENABLED: True

  SIZE_TRAIN: [ 384, 192 ]

  SIZE_TEST: [ 384, 192 ]

SOLVER:
  AMP:
    ENABLED: True
  IMS_PER_BATCH: 64

  MAX_EPOCH: 120

  CHECKPOINT_PERIOD: 20

  FREEZE_ITERS: 0

TEST:
  EVAL_PERIOD: 4
  IMS_PER_BATCH: 64

[11/10 16:56:43] fastreid INFO: Running with full config:
ATTN_OUTPUT: False
CUDNN_BENCHMARK: True
DATALOADER:
  NUM_INSTANCE: 16
  NUM_WORKERS: 8
  SAMPLER_TRAIN: NaiveIdentitySampler
  SET_WEIGHT: []
DATASETS:
  COMBINEALL: False
  NAMES: ('Market1501',)
  TESTS: ('Market1501',)
INPUT:
  AFFINE:
    ENABLED: False
  AUGMIX:
    ENABLED: False
    PROB: 0.0
  AUTOAUG:
    ENABLED: False
    PROB: 0.1
  CJ:
    BRIGHTNESS: 0.15
    CONTRAST: 0.15
    ENABLED: False
    HUE: 0.1
    PROB: 0.5
    SATURATION: 0.1
  CROP:
    ENABLED: False
    RATIO: [0.75, 1.3333333333333333]
    SCALE: [0.16, 1]
    SIZE: [224, 224]
  FLIP:
    ENABLED: True
    PROB: 0.5
  PADDING:
    ENABLED: True
    MODE: constant
    SIZE: 10
  REA:
    ENABLED: True
    PROB: 0.5
    VALUE: [123.675, 116.28, 103.53]
  RGPR:
    ENABLED: False
    PROB: 0.4
  RPT:
    ENABLED: True
    PROB: 0.5
  SIZE_TEST: [384, 192]
  SIZE_TRAIN: [384, 192]
KD:
  EMA:
    ENABLED: False
    MOMENTUM: 0.999
  MODEL_CONFIG: []
  MODEL_WEIGHTS: []
MISMTACH_OUTPUT: False
MODEL:
  BACKBONE:
    ADJ_KEEP: False
    ATTACH_ACTIVATION: False
    ATTNSHAPED_ACTIVATION: False
    ATT_DROP_RATE: 0.0
    DEPTH: 50x
    DROP_PATH_RATIO: 0.1
    DROP_RATIO: 0.0
    EMBEDDING_DIM: 512
    FEAT_DIM: 2048
    LAST_STRIDE: 1
    NAME: build_resnet_backbone
    NORM: syncBN
    PRETRAIN: True
    PRETRAIN_PATH: 
    SIE_COE: 3.0
    STRIDE_SIZE: (16, 16)
    WITH_IBN: True
    WITH_NL: True
    WITH_SE: False
  DETACH_ALL: False
  DETACH_ATTN: False
  DEVICE: cuda
  DROP:
    ENABLED: False
    H_RATIO: 0.15
    W_RATIO: 1.0
  FREEZE_LAYERS: ['backbone']
  HEADS:
    ADDTION_POOL: 
    ATTN: 8
    CLS_LAYER: CircleSoftmax
    EMBEDDING_DIM: 0
    GAN: False
    GAN_RATIO: 0.0
    MARGIN: 0.35
    NAME: EmbeddingHead
    NECK_FEAT: after
    NORM: syncBN
    NUM_CLASSES: 0
    POOL_LAYER: GeneralizedMeanPoolingP
    SCALE: 64
    WITH_BNNECK: True
  LOSSES:
    CE:
      ALPHA: 0.2
      ATTN_SCALE: 1.0
      EPSILON: 0.1
      MAIN_SCALE: 1.0
      SCALE: 1.0
    CENTER:
      SCALE: 0.0005
    CIRCLE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    COSFACE:
      GAMMA: 128
      MARGIN: 0.25
      SCALE: 1.0
    FL:
      ALPHA: 0.25
      GAMMA: 2
      SCALE: 1.0
    KL:
      MARGIN: 1.0
    NAME: ('CrossEntropyLoss', 'TripletLoss')
    TRI:
      ATTN: False
      HARD_MINING: True
      MARGIN: 0.0
      NORM_FEAT: False
      SCALE: 1.0
  META_ARCHITECTURE: Sbaseline
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.120000000000005, 57.375]
  QUEUE_SIZE: 8192
  SWIN:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 4
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  WEIGHTS: 
OUTPUT_DIR: logs/MarketT_Quick/STAGE/120_SBaseline
SOLVER:
  AMP:
    ENABLED: True
  BASE_LR: 0.00035
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 20
  CLIP_GRADIENTS:
    CLIP_TYPE: norm
    CLIP_VALUE: 5.0
    ENABLED: False
    NORM_TYPE: 2.0
  DELAY_EPOCHS: 30
  ETA_MIN_LR: 7e-07
  FREEZE_ITERS: 0
  GAMMA: 0.1
  HEADS_LR_FACTOR: 1.0
  IMS_PER_BATCH: 64
  MAX_EPOCH: 120
  MOMENTUM: 0.9
  NESTEROV: False
  OPT: Adam
  SCHED: CosineAnnealingLR
  STEPS: [40, 90]
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0005
  WEIGHT_DECAY_BIAS: 0.0005
  WEIGHT_DECAY_NORM: 0.0005
TEST:
  AQE:
    ALPHA: 3.0
    ENABLED: False
    QE_K: 5
    QE_TIME: 1
  EVAL_PERIOD: 4
  FLIP:
    ENABLED: False
  IMS_PER_BATCH: 64
  METRIC: cosine
  PRECISE_BN:
    DATASET: Market1501
    ENABLED: False
    NUM_ITER: 300
  RERANK:
    ENABLED: False
    K1: 20
    K2: 6
    LAMBDA: 0.3
  ROC:
    ENABLED: False
[11/10 16:56:43] fastreid.engine.defaults INFO: Prepare training set
[11/10 16:56:43] fastreid.data.build INFO: Using training sampler NaiveIdentitySampler
[11/10 16:56:43] fastreid.engine.defaults INFO: Auto-scaling the num_classes=751
[11/10 16:56:43] fastreid.modeling.backbones.resnet INFO: Loading pretrained model from /home/ckl/.cache/torch/checkpoints/resnet50_ibn_a-d9d0bb7b.pth
[11/10 16:56:44] fastreid.modeling.backbones.resnet INFO: Some model parameters or buffers are not found in the checkpoint:
  [34mNL_2.0.g.{weight, bias}[0m
  [34mNL_2.0.W.0.{weight, bias}[0m
  [34mNL_2.0.W.1.{weight, bias, running_mean, running_var}[0m
  [34mNL_2.0.theta.{weight, bias}[0m
  [34mNL_2.0.phi.{weight, bias}[0m
  [34mNL_2.1.g.{weight, bias}[0m
  [34mNL_2.1.W.0.{weight, bias}[0m
  [34mNL_2.1.W.1.{weight, bias, running_mean, running_var}[0m
  [34mNL_2.1.theta.{weight, bias}[0m
  [34mNL_2.1.phi.{weight, bias}[0m
  [34mNL_3.0.g.{weight, bias}[0m
  [34mNL_3.0.W.0.{weight, bias}[0m
  [34mNL_3.0.W.1.{weight, bias, running_mean, running_var}[0m
  [34mNL_3.0.theta.{weight, bias}[0m
  [34mNL_3.0.phi.{weight, bias}[0m
  [34mNL_3.1.g.{weight, bias}[0m
  [34mNL_3.1.W.0.{weight, bias}[0m
  [34mNL_3.1.W.1.{weight, bias, running_mean, running_var}[0m
  [34mNL_3.1.theta.{weight, bias}[0m
  [34mNL_3.1.phi.{weight, bias}[0m
  [34mNL_3.2.g.{weight, bias}[0m
  [34mNL_3.2.W.0.{weight, bias}[0m
  [34mNL_3.2.W.1.{weight, bias, running_mean, running_var}[0m
  [34mNL_3.2.theta.{weight, bias}[0m
  [34mNL_3.2.phi.{weight, bias}[0m
[11/10 16:56:44] fastreid.modeling.backbones.resnet INFO: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc.{weight, bias}[0m
[11/10 16:56:44] fastreid.engine.defaults INFO: Model:
Sbaseline(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (NL_1): ModuleList()
    (NL_2): ModuleList(
      (0): Non_local(
        (g): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 512, kernel_size=(1, 1), stride=(1, 1))
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): Non_local(
        (g): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 512, kernel_size=(1, 1), stride=(1, 1))
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_3): ModuleList(
      (0): Non_local(
        (g): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1))
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): Non_local(
        (g): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1))
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): Non_local(
        (g): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (W): Sequential(
          (0): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1))
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (theta): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
        (phi): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (NL_4): ModuleList()
  )
  (heads): EmbeddingHead(
    (pool_layer): GeneralizedMeanPoolingP(Parameter containing:
    tensor([3.], device='cuda:1', requires_grad=True), output_size=(1, 1))
    (bottleneck): Sequential(
      (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): CircleSoftmax(num_classes=751, scale=64, margin=0.35)
  )
  (upSamper3): Embedding(
    (embedding): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (bn): IBN(
      (IN): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (upSamper2): UpSamper(
    (up2): Sequential(
      (0): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    )
    (bn): IBN(
      (IN): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (upSamper1): UpSamper(
    (up2): Sequential(
      (0): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    )
    (bn): IBN(
      (IN): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (attention_maker): BasicConv2d(
    (conv): Conv2d(2048, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): IBN(
      (IN): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (attach): Attach(
    (pool): GeneralizedMeanPoolingP(Parameter containing:
    tensor([3.], device='cuda:1', requires_grad=True), output_size=(1, 1))
    (embedding_layer): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (attnShaped3): AttnShaped()
  (attnShaped2): AttnShaped()
  (attnShaped1): AttnShaped()
  (backbone1): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
  )
  (head1): EmbeddingHead(
    (pool_layer): GeneralizedMeanPoolingP(Parameter containing:
    tensor([3.], device='cuda:1', requires_grad=True), output_size=(1, 1))
    (bottleneck): Sequential(
      (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): CircleSoftmax(num_classes=751, scale=64, margin=0.35)
  )
  (backbone2): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): IBN(
          (IN): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (BN): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
    (1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
  )
  (head2): EmbeddingHead(
    (pool_layer): GeneralizedMeanPoolingP(Parameter containing:
    tensor([3.], device='cuda:1', requires_grad=True), output_size=(1, 1))
    (bottleneck): Sequential(
      (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): CircleSoftmax(num_classes=751, scale=64, margin=0.35)
  )
  (backbone3): Sequential(
    (0): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (se): Identity()
      )
    )
  )
  (head3): EmbeddingHead(
    (pool_layer): GeneralizedMeanPoolingP(Parameter containing:
    tensor([3.], device='cuda:1', requires_grad=True), output_size=(1, 1))
    (bottleneck): Sequential(
      (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): CircleSoftmax(num_classes=751, scale=64, margin=0.35)
  )
  (attn_head): EmbeddingHead(
    (pool_layer): Identity()
    (bottleneck): Sequential(
      (0): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (cls_layer): CircleSoftmax(num_classes=751, scale=64, margin=0.35)
  )
  (embedding4): Embedding(
    (embedding): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): IBN(
      (IN): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (embedding3): Embedding(
    (embedding): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): IBN(
      (IN): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (embedding2): Embedding(
    (embedding): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): IBN(
      (IN): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
  (embedding1): Embedding(
    (embedding): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): IBN(
      (IN): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (BN): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU()
  )
)
[11/10 16:56:57] fastreid.utils.checkpoint INFO: No checkpoint found. Training model from scratch
[11/10 16:56:57] fastreid.engine.train_loop INFO: Starting training from epoch 0
[11/10 17:03:07] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:03:07] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:03:17] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1405 s / batch. ETA=0:00:41
[11/10 17:03:47] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1397 s / batch. ETA=0:00:10
[11/10 17:03:59] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:42.706955 (0.143794 s / batch per device, on 2 devices)
[11/10 17:03:59] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:42 (0.142784 s / batch per device, on 2 devices)
[11/10 17:10:18] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:10:18] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:10:27] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1402 s / batch. ETA=0:00:41
[11/10 17:10:57] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1393 s / batch. ETA=0:00:10
[11/10 17:11:08] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.562676 (0.139942 s / batch per device, on 2 devices)
[11/10 17:11:08] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139043 s / batch per device, on 2 devices)
[11/10 17:17:27] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:17:27] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:17:36] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1402 s / batch. ETA=0:00:41
[11/10 17:18:06] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1398 s / batch. ETA=0:00:10
[11/10 17:18:17] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.687557 (0.140362 s / batch per device, on 2 devices)
[11/10 17:18:17] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139452 s / batch per device, on 2 devices)
[11/10 17:24:36] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:24:36] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:24:45] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1400 s / batch. ETA=0:00:41
[11/10 17:25:15] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 17:25:26] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.627078 (0.140159 s / batch per device, on 2 devices)
[11/10 17:25:26] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139218 s / batch per device, on 2 devices)
[11/10 17:31:45] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:31:45] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:31:54] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1401 s / batch. ETA=0:00:41
[11/10 17:32:24] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1396 s / batch. ETA=0:00:10
[11/10 17:32:35] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.686607 (0.140359 s / batch per device, on 2 devices)
[11/10 17:32:35] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139309 s / batch per device, on 2 devices)
[11/10 17:39:02] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:39:02] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:39:10] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1389 s / batch. ETA=0:00:41
[11/10 17:39:41] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1393 s / batch. ETA=0:00:10
[11/10 17:39:51] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.553165 (0.139910 s / batch per device, on 2 devices)
[11/10 17:39:51] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.138997 s / batch per device, on 2 devices)
[11/10 17:46:10] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:46:11] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:46:19] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1396 s / batch. ETA=0:00:41
[11/10 17:46:49] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 17:47:00] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.647991 (0.140229 s / batch per device, on 2 devices)
[11/10 17:47:00] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139313 s / batch per device, on 2 devices)
[11/10 17:53:20] fastreid.engine.defaults INFO: Prepare testing set
[11/10 17:53:20] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 17:53:29] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1404 s / batch. ETA=0:00:41
[11/10 17:53:59] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 17:54:10] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.606531 (0.140089 s / batch per device, on 2 devices)
[11/10 17:54:10] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139203 s / batch per device, on 2 devices)
[11/10 18:00:28] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:00:28] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:00:36] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1390 s / batch. ETA=0:00:41
[11/10 18:01:06] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 18:01:17] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.633675 (0.140181 s / batch per device, on 2 devices)
[11/10 18:01:17] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139264 s / batch per device, on 2 devices)
[11/10 18:07:36] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:07:37] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:07:45] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1388 s / batch. ETA=0:00:40
[11/10 18:08:15] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 18:08:26] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.691744 (0.140376 s / batch per device, on 2 devices)
[11/10 18:08:26] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139398 s / batch per device, on 2 devices)
[11/10 18:14:52] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:14:52] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:15:00] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1402 s / batch. ETA=0:00:41
[11/10 18:15:30] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 18:15:41] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.617843 (0.140127 s / batch per device, on 2 devices)
[11/10 18:15:41] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139255 s / batch per device, on 2 devices)
[11/10 18:22:00] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:22:01] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:22:09] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1404 s / batch. ETA=0:00:41
[11/10 18:22:39] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1396 s / batch. ETA=0:00:10
[11/10 18:22:50] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.632383 (0.140176 s / batch per device, on 2 devices)
[11/10 18:22:50] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139317 s / batch per device, on 2 devices)
[11/10 18:29:09] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:29:09] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:29:17] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1401 s / batch. ETA=0:00:41
[11/10 18:29:47] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1393 s / batch. ETA=0:00:10
[11/10 18:29:58] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.563183 (0.139943 s / batch per device, on 2 devices)
[11/10 18:29:58] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139053 s / batch per device, on 2 devices)
[11/10 18:36:17] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:36:17] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:36:26] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1401 s / batch. ETA=0:00:41
[11/10 18:36:56] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1396 s / batch. ETA=0:00:10
[11/10 18:37:07] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.647607 (0.140228 s / batch per device, on 2 devices)
[11/10 18:37:07] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139288 s / batch per device, on 2 devices)
[11/10 18:43:25] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:43:26] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:43:34] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1408 s / batch. ETA=0:00:41
[11/10 18:44:04] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 18:44:15] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.601447 (0.140072 s / batch per device, on 2 devices)
[11/10 18:44:15] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139149 s / batch per device, on 2 devices)
[11/10 18:50:40] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:50:40] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:50:49] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1399 s / batch. ETA=0:00:40
[11/10 18:51:19] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1394 s / batch. ETA=0:00:10
[11/10 18:51:30] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.570162 (0.139967 s / batch per device, on 2 devices)
[11/10 18:51:30] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139076 s / batch per device, on 2 devices)
[11/10 18:57:49] fastreid.engine.defaults INFO: Prepare testing set
[11/10 18:57:49] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 18:57:57] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1404 s / batch. ETA=0:00:41
[11/10 18:58:27] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1394 s / batch. ETA=0:00:10
[11/10 18:58:38] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.586511 (0.140022 s / batch per device, on 2 devices)
[11/10 18:58:38] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139153 s / batch per device, on 2 devices)
[11/10 19:04:57] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:04:57] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:05:06] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1396 s / batch. ETA=0:00:40
[11/10 19:05:36] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1393 s / batch. ETA=0:00:10
[11/10 19:05:47] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.547903 (0.139892 s / batch per device, on 2 devices)
[11/10 19:05:47] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139035 s / batch per device, on 2 devices)
[11/10 19:12:06] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:12:06] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:12:14] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1391 s / batch. ETA=0:00:40
[11/10 19:12:44] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 19:12:55] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.627137 (0.140159 s / batch per device, on 2 devices)
[11/10 19:12:55] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139286 s / batch per device, on 2 devices)
[11/10 19:19:14] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:19:14] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:19:23] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1395 s / batch. ETA=0:00:41
[11/10 19:19:53] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1393 s / batch. ETA=0:00:10
[11/10 19:20:03] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.550197 (0.139900 s / batch per device, on 2 devices)
[11/10 19:20:03] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139032 s / batch per device, on 2 devices)
[11/10 19:26:28] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:26:28] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:26:36] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1400 s / batch. ETA=0:00:40
[11/10 19:27:06] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1393 s / batch. ETA=0:00:10
[11/10 19:27:17] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.578453 (0.139995 s / batch per device, on 2 devices)
[11/10 19:27:17] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139093 s / batch per device, on 2 devices)
[11/10 19:33:36] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:33:37] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:33:45] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1389 s / batch. ETA=0:00:40
[11/10 19:34:15] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1394 s / batch. ETA=0:00:10
[11/10 19:34:26] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.579321 (0.139998 s / batch per device, on 2 devices)
[11/10 19:34:26] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139105 s / batch per device, on 2 devices)
[11/10 19:40:44] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:40:45] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:40:53] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1401 s / batch. ETA=0:00:41
[11/10 19:41:23] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1392 s / batch. ETA=0:00:10
[11/10 19:41:34] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.535832 (0.139851 s / batch per device, on 2 devices)
[11/10 19:41:34] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.138900 s / batch per device, on 2 devices)
[11/10 19:47:53] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:47:53] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:48:02] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1385 s / batch. ETA=0:00:40
[11/10 19:48:32] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1391 s / batch. ETA=0:00:10
[11/10 19:48:42] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.487757 (0.139689 s / batch per device, on 2 devices)
[11/10 19:48:42] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.138826 s / batch per device, on 2 devices)
[11/10 19:55:01] fastreid.engine.defaults INFO: Prepare testing set
[11/10 19:55:01] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 19:55:10] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1397 s / batch. ETA=0:00:41
[11/10 19:55:40] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1394 s / batch. ETA=0:00:10
[11/10 19:55:51] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.589192 (0.140031 s / batch per device, on 2 devices)
[11/10 19:55:51] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139137 s / batch per device, on 2 devices)
[11/10 20:02:15] fastreid.engine.defaults INFO: Prepare testing set
[11/10 20:02:15] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 20:02:23] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1389 s / batch. ETA=0:00:40
[11/10 20:02:53] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1394 s / batch. ETA=0:00:10
[11/10 20:03:04] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.594205 (0.140048 s / batch per device, on 2 devices)
[11/10 20:03:04] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139155 s / batch per device, on 2 devices)
[11/10 20:09:23] fastreid.engine.defaults INFO: Prepare testing set
[11/10 20:09:23] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 20:09:31] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1404 s / batch. ETA=0:00:41
[11/10 20:10:01] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1393 s / batch. ETA=0:00:10
[11/10 20:10:12] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.538751 (0.139861 s / batch per device, on 2 devices)
[11/10 20:10:12] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.138972 s / batch per device, on 2 devices)
[11/10 20:16:31] fastreid.engine.defaults INFO: Prepare testing set
[11/10 20:16:32] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 20:16:40] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1401 s / batch. ETA=0:00:40
[11/10 20:17:10] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 20:17:21] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.589356 (0.140032 s / batch per device, on 2 devices)
[11/10 20:17:21] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139047 s / batch per device, on 2 devices)
[11/10 20:23:40] fastreid.engine.defaults INFO: Prepare testing set
[11/10 20:23:40] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 20:23:49] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1400 s / batch. ETA=0:00:41
[11/10 20:24:19] fastreid.evaluation.evaluator INFO: Inference done 225/302. 0.1395 s / batch. ETA=0:00:10
[11/10 20:24:30] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.616908 (0.140124 s / batch per device, on 2 devices)
[11/10 20:24:30] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.139188 s / batch per device, on 2 devices)
[11/10 20:30:51] fastreid.engine.defaults INFO: Prepare testing set
[11/10 20:30:51] fastreid.evaluation.evaluator INFO: Start inference on 19281 images
[11/10 20:31:00] fastreid.evaluation.evaluator INFO: Inference done 11/302. 0.1402 s / batch. ETA=0:00:41
[11/10 20:31:30] fastreid.evaluation.evaluator INFO: Inference done 226/302. 0.1393 s / batch. ETA=0:00:10
[11/10 20:31:40] fastreid.evaluation.evaluator INFO: Total inference time: 0:00:41.534885 (0.139848 s / batch per device, on 2 devices)
[11/10 20:31:40] fastreid.evaluation.evaluator INFO: Total inference pure compute time: 0:00:41 (0.138938 s / batch per device, on 2 devices)
[11/10 20:31:46] fastreid.engine.hooks INFO: Overall training speed: 24238 iterations in 3:06:46 (0.4624 s / it)
[11/10 20:31:46] fastreid.engine.hooks INFO: Total training time: 3:34:42 (0:27:55 on hooks)
